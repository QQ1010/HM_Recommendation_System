{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2adde42",
   "metadata": {},
   "source": [
    "### H&M Recommendation System — 02 Recall (Candidate Generation)\n",
    "\n",
    "In this notebook, I design and evaluate several **candidate generation (recall)** strategies\n",
    "for the H&M Personalized Fashion Recommendations task.\n",
    "\n",
    "Based on the EDA from `01_EDA.ipynb`, I observed that:\n",
    "\n",
    "- Customer behavior shows a strong **long-tail distribution** with clear personal preferences\n",
    "  and repeated purchases of similar product types.\n",
    "- Article popularity is highly skewed, with a small subset of items dominating sales.\n",
    "- The transaction timeline exhibits a strong **weekly pattern**, as well as several large spikes\n",
    "  likely corresponding to promotional events.\n",
    "- Articles have rich and well-structured **categorical metadata** (e.g. product groups, sections,\n",
    "  garment groups), which provide useful semantic information.\n",
    "- Customers frequently buy multiple items in a single day, indicating strong **co-purchase patterns**.\n",
    "\n",
    "These observations motivate the following recall strategies:\n",
    "\n",
    "1. **User-history-based recall**  \n",
    "   - Use each customer's historical purchases (from the training period) as personalized candidates.\n",
    "\n",
    "2. **Recent popularity recall**  \n",
    "   - Use globally trending items from a recent time window (e.g. last 28 days before validation)\n",
    "     as a popularity-based candidate pool.\n",
    "\n",
    "3. **Category-based recall**  \n",
    "   - Use item metadata (e.g. product_type or product_group) to recommend popular items from\n",
    "     the categories that a user frequently buys.\n",
    "\n",
    "4. **Co-purchase-based recall**  \n",
    "   - Use simple co-purchase statistics (\"customers who bought A also bought B\") to find items\n",
    "     related to a user's previously purchased products.\n",
    "\n",
    "Together, these recall pools aim to cover:\n",
    "- **Personal preferences** (user history)\n",
    "- **Global trends** (recent popularity)\n",
    "- **Semantic similarity** (category-based)\n",
    "- **Behavioral complementarity** (co-purchase)\n",
    "\n",
    "The final candidate set (top 100 ~ 500) for each customer will be built by combining these pools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a24a6c",
   "metadata": {},
   "source": [
    "#### Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aaabfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'articles.csv',\n",
       " 'customers.csv',\n",
       " 'transactions_train.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 5)\n",
    "pd.set_option(\"display.max_rows\", 5)\n",
    "\n",
    "DATA_DIR = \"../hm_data\"  # 改成你的實際資料夾\n",
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba5e176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transactions: (31788324, 5)\n",
      "articles: (105542, 25)\n"
     ]
    }
   ],
   "source": [
    "# Load transactions\n",
    "transactions = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"transactions_train.csv\"),\n",
    "    parse_dates=[\"t_dat\"]\n",
    ")\n",
    "print(\"transactions:\", transactions.shape)\n",
    "\n",
    "# Load articles metadata (for category-based recall)\n",
    "articles = pd.read_csv(os.path.join(DATA_DIR, \"articles.csv\"))\n",
    "print(\"articles:\", articles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e253b1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2018-09-20 00:00:00'), Timestamp('2020-09-22 00:00:00'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions[\"t_dat\"].min(), transactions[\"t_dat\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7542bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID_START: 2020-09-16 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (31548013, 5) Valid: (240311, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split Train / Valid\n",
    "VALID_START = pd.to_datetime(\"2020-09-16\")\n",
    "print(\"VALID_START:\", VALID_START)\n",
    "\n",
    "train_df = transactions[transactions[\"t_dat\"] < VALID_START].copy()\n",
    "valid_df = transactions[transactions[\"t_dat\"] >= VALID_START].copy()\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Valid:\", valid_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7cb408",
   "metadata": {},
   "source": [
    "#### Step 2: Validation Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06230ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68984"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_gt = (\n",
    "    valid_df.groupby(\"customer_id\")[\"article_id\"]\n",
    "    .apply(lambda x: set(x.astype(int)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "len(valid_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952665c",
   "metadata": {},
   "source": [
    "#### Step 3: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Recall@K & Hit Rate\n",
    "def evaluate_recall(candidates_dict, gt_dict, k=100, return_recalls=False):\n",
    "    \"\"\"\n",
    "    candidates_dict: {customer_id: [candidate_item_ids]}\n",
    "    gt_dict: {customer_id: set(ground_truth_items)}\n",
    "    \"\"\"\n",
    "    recalls = []\n",
    "    hits = 0\n",
    "    total_users = 0\n",
    "\n",
    "    for cust, gt_items in gt_dict.items():\n",
    "        if cust not in candidates_dict:\n",
    "            continue\n",
    "        total_users += 1\n",
    "\n",
    "        cand = candidates_dict[cust][:k]\n",
    "        cand_set = set(cand)\n",
    "        inter = cand_set & gt_items\n",
    "\n",
    "        if len(gt_items) > 0:\n",
    "            recall_u = len(inter) / len(gt_items)\n",
    "            recalls.append(recall_u)\n",
    "\n",
    "        if len(inter) > 0:\n",
    "            hits += 1\n",
    "\n",
    "    mean_recall = float(np.mean(recalls)) if recalls else 0.0\n",
    "    hit_rate = hits / total_users if total_users > 0 else 0.0\n",
    "\n",
    "    result = {\n",
    "        f\"mean_recall@{k}\": mean_recall,\n",
    "        f\"hit_rate@{k}\": hit_rate,\n",
    "        \"num_users\": total_users,\n",
    "    }\n",
    "    if return_recalls:\n",
    "        return result, recalls\n",
    "    return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
