{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db1e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "# 讓結果顯示好看\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 路徑（照你的專案習慣改）\n",
    "DATA_DIR = \"../data\"\n",
    "RANKING_DIR = os.path.join(DATA_DIR, \"ranking\")\n",
    "EXP_DIR = \"../experiments\"\n",
    "MODEL_DIR = \"../models\"\n",
    "CFG_DIR = os.path.join(EXP_DIR, \"configs\")\n",
    "\n",
    "os.makedirs(EXP_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(CFG_DIR, exist_ok=True)\n",
    "\n",
    "RESULTS_CSV = os.path.join(EXP_DIR, \"exp_results.csv\")\n",
    "\n",
    "VALID_START = pd.to_datetime(\"2020-09-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c086e4",
   "metadata": {},
   "source": [
    "### Step 1: Prepare train and valid dataset for Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df617764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save recall results\n",
    "def save_pickle(obj, path, overwrite=False):\n",
    "    if os.path.exists(path) and not overwrite:\n",
    "        print(f\"[Skip] {path} already exists.\")\n",
    "        return\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b87a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 14\n",
      "['tx_cnt', 'unique_items', 'recency_days', 'product_type_no', 'colour_group_code', 'department_no', 'index_group_no', 'garment_group_no', 'item_popularity', 'unique_buyers', 'item_recency_days', 'ui_cnt', 'ui_recency_days', 'product_group_id']\n"
     ]
    }
   ],
   "source": [
    "rank_df = load_pickle(os.path.join(RANKING_DIR, \"rank_df.pkl\"))\n",
    "\n",
    "drop_cols = [\"customer_id\", \"article_id\", \"label\"]\n",
    "\n",
    "feature_cols = [c for c in rank_df.columns if c not in drop_cols]\n",
    "print(\"Num features:\", len(feature_cols))\n",
    "print(feature_cols)\n",
    "\n",
    "rank_df = rank_df.sort_values(\"customer_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f8abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = rank_df[\"customer_id\"].unique()\n",
    "rng = np.random.default_rng(SEED)\n",
    "rng.shuffle(customers)\n",
    "\n",
    "cut = int(len(customers) * 0.8)\n",
    "train_customers = set(customers[:cut])\n",
    "\n",
    "train_df = rank_df[rank_df[\"customer_id\"].isin(train_customers)].sort_values(\"customer_id\").reset_index(drop=True)\n",
    "val_df   = rank_df[~rank_df[\"customer_id\"].isin(train_customers)].sort_values(\"customer_id\").reset_index(drop=True)\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[\"label\"].values\n",
    "group_train = train_df.groupby(\"customer_id\").size().tolist()\n",
    "\n",
    "X_val = val_df[feature_cols]\n",
    "y_val = val_df[\"label\"].values\n",
    "group_val = val_df.groupby(\"customer_id\").size().tolist()\n",
    "\n",
    "rank_df_val_for_eval = val_df[[\"customer_id\", \"article_id\", \"label\"]].copy()\n",
    "\n",
    "assert sum(group_train) == len(X_train)\n",
    "assert sum(group_val) == len(X_val)\n",
    "\n",
    "\n",
    "# X_all = rank_df[feature_cols]\n",
    "# y_all = rank_df[\"label\"].values\n",
    "\n",
    "# group_sizes_all = rank_df.groupby(\"customer_id\").size().tolist()\n",
    "\n",
    "# print(\"X_all shape:\", X_all.shape)\n",
    "# print(\"y_all shape:\", y_all.shape)\n",
    "# print(\"num groups (customers):\", len(group_sizes_all))\n",
    "\n",
    "# # shuffle and 80% training and 20% valid\n",
    "# customers = rank_df[\"customer_id\"].unique()\n",
    "# rng = np.random.default_rng(42)   # fix random seed\n",
    "# rng.shuffle(customers)\n",
    "\n",
    "# cut = int(len(customers) * 0.8)\n",
    "# train_customers = set(customers[:cut])\n",
    "# val_customers   = set(customers[cut:])\n",
    "\n",
    "# print(len(train_customers), len(val_customers))\n",
    "\n",
    "# # Mask and Split\n",
    "# train_mask = rank_df[\"customer_id\"].isin(train_customers)\n",
    "# val_mask   = ~train_mask\n",
    "\n",
    "# X_train = X_all[train_mask]\n",
    "# y_train = y_all[train_mask]\n",
    "\n",
    "# X_val = X_all[val_mask]\n",
    "# y_val = y_all[val_mask]\n",
    "\n",
    "# print(\"Train shape:\", X_train.shape, \" Val shape:\", X_val.shape)\n",
    "\n",
    "# group_train = rank_df[train_mask].groupby(\"customer_id\").size().tolist()\n",
    "# group_val   = rank_df[val_mask].groupby(\"customer_id\").size().tolist()\n",
    "\n",
    "# print(len(group_train), len(group_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e238b1",
   "metadata": {},
   "source": [
    "### Step 2: Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7df7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual_set, predicted_list, k=12):\n",
    "    if not actual_set:\n",
    "        return 0.0\n",
    "    score = 0.0\n",
    "    hit = 0\n",
    "    seen = set()\n",
    "    for i, p in enumerate(predicted_list[:k], start=1):\n",
    "        if p in seen:\n",
    "            continue\n",
    "        seen.add(p)\n",
    "        if p in actual_set:\n",
    "            hit += 1\n",
    "            score += hit / i\n",
    "    return score / min(len(actual_set), k)\n",
    "\n",
    "\n",
    "def mapk_from_scored_df(df, k=12):\n",
    "    ap_list = []\n",
    "    for cust, g in df.groupby(\"customer_id\"):\n",
    "        actual = set(g.loc[g[\"label\"] == 1, \"article_id\"].tolist())\n",
    "        pred = g.sort_values(\"score\", ascending=False)[\"article_id\"].tolist()\n",
    "        ap_list.append(apk(actual, pred, k=k))\n",
    "    return sum(ap_list) / len(ap_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64e293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_result_row(row: dict, csv_path: str = RESULTS_CSV):\n",
    "    df_row = pd.DataFrame([row])\n",
    "    if os.path.exists(csv_path):\n",
    "        df_row.to_csv(csv_path, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(csv_path, mode=\"w\", header=True, index=False)\n",
    "\n",
    "def save_json(obj: dict, path: str, overwrite: bool = False):\n",
    "    if (not overwrite) and os.path.exists(path):\n",
    "        return\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2, default=str)\n",
    "\n",
    "def candidate_stats(df):\n",
    "    per_cust = df.groupby(\"customer_id\").size()\n",
    "    return {\n",
    "        \"val_avg_candidates\": float(per_cust.mean()),\n",
    "        \"val_med_candidates\": float(per_cust.median()),\n",
    "        \"val_min_candidates\": int(per_cust.min()),\n",
    "        \"val_max_candidates\": int(per_cust.max()),\n",
    "        \"val_pos_rate\": float(df[\"label\"].mean()),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae550971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    exp_id: str,\n",
    "    exp_name: str,\n",
    "    recall_name: str,\n",
    "    lgb_params: dict,\n",
    "    X_train, y_train, group_train,\n",
    "    X_val, y_val, group_val,\n",
    "    rank_df_val_for_eval: pd.DataFrame = None,  # optional: df with customer_id/article_id/label for val rows\n",
    "    save_model: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train LGBMRanker + evaluate + save config/model + append results to CSV.\n",
    "    exp_id: e.g. \"E01\"\n",
    "    exp_name: e.g. \"baseline\"\n",
    "    recall_name: e.g. \"history+recent_pop+category+copurchase\"\n",
    "    lgb_params: parameters for lgb.LGBMRanker(...)\n",
    "    rank_df_val_for_eval: if provided, will compute manual MAP@12 using predicted scores\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # --- train ---\n",
    "    ranker = lgb.LGBMRanker(**lgb_params)\n",
    "    ranker.fit(\n",
    "        X_train, y_train,\n",
    "        group=group_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_group=[group_val],\n",
    "        eval_at=lgb_params.get(\"eval_at\", [12]),\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50, verbose=True),\n",
    "            lgb.log_evaluation(period=50)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_time_sec = time.time() - start\n",
    "    best_iter = getattr(ranker, \"best_iteration_\", None)\n",
    "    pred_kwargs = {}\n",
    "    if best_iter is not None:\n",
    "        pred_kwargs[\"num_iteration\"] = best_iter\n",
    "\n",
    "    # --- evaluate ---\n",
    "    val_scores = ranker.predict(X_val, **pred_kwargs)\n",
    "    manual_map12 = None\n",
    "    stats = {}\n",
    "    if rank_df_val_for_eval is not None:\n",
    "        tmp = rank_df_val_for_eval.copy()\n",
    "        tmp[\"score\"] = val_scores\n",
    "\n",
    "        manual_map12 = mapk_from_scored_df(tmp, k=12)\n",
    "        stats = candidate_stats(tmp)\n",
    "\n",
    "    # --- save config ---\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    cfg = {\n",
    "        \"exp_id\": exp_id,\n",
    "        \"exp_name\": exp_name,\n",
    "        \"recall_name\": recall_name,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"lgb_params\": lgb_params,\n",
    "        \"num_train_rows\": int(X_train.shape[0]),\n",
    "        \"num_val_rows\": int(X_val.shape[0]),\n",
    "        \"num_features\": int(X_train.shape[1]),\n",
    "        \"feature_cols\": list(X_train.columns),\n",
    "    }\n",
    "    cfg_path = os.path.join(CFG_DIR, f\"{exp_id}_{exp_name}.json\")\n",
    "    save_json(cfg, cfg_path, overwrite=True)\n",
    "\n",
    "    # --- save model ---\n",
    "    model_path = None\n",
    "    if save_model:\n",
    "        model_path = os.path.join(MODEL_DIR, f\"{exp_id}_{exp_name}.pkl\")\n",
    "        joblib.dump(ranker, model_path)\n",
    "\n",
    "    # --- append results row ---\n",
    "    row = {\n",
    "        \"exp_id\": exp_id,\n",
    "        \"exp_name\": exp_name,\n",
    "        \"recall_name\": recall_name,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"best_iteration\": best_iter,\n",
    "        \"train_time_sec\": round(train_time_sec, 2),\n",
    "        \"val_map12_manual\": manual_map12,\n",
    "        \"num_train_rows\": int(X_train.shape[0]),\n",
    "        \"num_val_rows\": int(X_val.shape[0]),\n",
    "        \"num_features\": int(X_train.shape[1]),\n",
    "        \"model_path\": model_path,\n",
    "        \"config_path\": cfg_path,\n",
    "    }\n",
    "    row.update(stats)\n",
    "    append_result_row(row)\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e220218d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 14,\n",
       " 'user_only': 3,\n",
       " 'item_attr_only': 6,\n",
       " 'item_pop_only': 3,\n",
       " 'ui_only': 2,\n",
       " 'user+ui': 5,\n",
       " 'item_attr+pop': 9,\n",
       " 'all_minus_ui': 12,\n",
       " 'all_minus_pop': 11}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_ALL = [\n",
    "    'tx_cnt', 'unique_items', 'recency_days',\n",
    "    'product_type_no', 'colour_group_code', 'department_no', 'index_group_no', 'garment_group_no', 'product_group_id',\n",
    "    'item_popularity', 'unique_buyers', 'item_recency_days',\n",
    "    'ui_cnt', 'ui_recency_days'\n",
    "]\n",
    "\n",
    "F_USER = ['tx_cnt', 'unique_items', 'recency_days']\n",
    "F_ITEM_ATTR = ['product_type_no', 'product_group_id', 'colour_group_code', 'department_no', 'index_group_no', 'garment_group_no']\n",
    "F_ITEM_POP = ['item_popularity', 'unique_buyers', 'item_recency_days']\n",
    "F_UI = ['ui_cnt', 'ui_recency_days']\n",
    "\n",
    "FEATURE_SETS = {\n",
    "    \"all\": F_ALL,\n",
    "    \"user_only\": F_USER,\n",
    "    \"item_attr_only\": F_ITEM_ATTR,\n",
    "    \"item_pop_only\": F_ITEM_POP,\n",
    "    \"ui_only\": F_UI,\n",
    "    \"user+ui\": F_USER + F_UI,\n",
    "    \"item_attr+pop\": F_ITEM_ATTR + F_ITEM_POP,\n",
    "    \"all_minus_ui\": [c for c in F_ALL if c not in set(F_UI)],\n",
    "    \"all_minus_pop\": [c for c in F_ALL if c not in set(F_ITEM_POP)],\n",
    "}\n",
    "{ k: len(v) for k,v in FEATURE_SETS.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e8c553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2185\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.928125\n",
      "[100]\tvalid_0's ndcg@12: 0.928376\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's ndcg@12: 0.92848\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E01 baseline_all all 0.03691019111445646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.893668\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@12: 0.893668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E02 user_only user_only 0.0065428509216108035\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 386\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.908278\n",
      "[100]\tvalid_0's ndcg@12: 0.908745\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's ndcg@12: 0.909141\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E03 item_attr_only item_attr_only 0.01904076377974687\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.918156\n",
      "[100]\tvalid_0's ndcg@12: 0.917268\n",
      "[150]\tvalid_0's ndcg@12: 0.917091\n",
      "[200]\tvalid_0's ndcg@12: 0.917122\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's ndcg@12: 0.919005\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E04 item_pop_only item_pop_only 0.02709499311514235\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.917613\n",
      "[100]\tvalid_0's ndcg@12: 0.917685\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's ndcg@12: 0.918162\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E05 ui_only ui_only 0.027275898295503954\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1035\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.917478\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's ndcg@12: 0.918133\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E06 user_plus_ui user+ui 0.027600650230932135\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1150\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.921746\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's ndcg@12: 0.922323\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E07 item_attr_plus_pop item_attr+pop 0.030441786800868446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1915\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.921995\n",
      "[100]\tvalid_0's ndcg@12: 0.922466\n",
      "[150]\tvalid_0's ndcg@12: 0.922683\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's ndcg@12: 0.923155\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E08 all_minus_ui all_minus_ui 0.030972516942655313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1421\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.923634\n",
      "[100]\tvalid_0's ndcg@12: 0.923485\n",
      "[150]\tvalid_0's ndcg@12: 0.923666\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's ndcg@12: 0.924323\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E09 all_minus_pop all_minus_pop 0.0330972623971101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2185\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.927521\n",
      "[100]\tvalid_0's ndcg@12: 0.927837\n",
      "[150]\tvalid_0's ndcg@12: 0.928269\n",
      "[200]\tvalid_0's ndcg@12: 0.928258\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's ndcg@12: 0.928623\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E10 stronger_reg all 0.03700724652308324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2185\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's ndcg@12: 0.927931\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's ndcg@12: 0.928547\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E11 lr_0.03_more_trees all 0.036904771056216895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2185\n",
      "[LightGBM] [Info] Number of data points in the train set: 2822015, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@12: 0.924573\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's ndcg@12: 0.925341\n",
      "[150]\tvalid_0's ndcg@12: 0.926228\n",
      "[200]\tvalid_0's ndcg@12: 0.927195\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[250]\tvalid_0's ndcg@12: 0.927153\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's ndcg@12: 0.927387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/r12944014/miniconda3/envs/hm_rec/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E12 extra_trees all 0.03607907892643696\n"
     ]
    }
   ],
   "source": [
    "BASE_PARAMS = dict(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    eval_at=[12],\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=2000,\n",
    "    num_leaves=63,\n",
    "    min_data_in_leaf=50,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=SEED,\n",
    "    bagging_seed=SEED,\n",
    "    feature_fraction_seed=SEED,\n",
    "    data_random_seed=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "EXPS = [\n",
    "    (\"E01\", \"baseline_all\",          \"all\",            {}),\n",
    "    (\"E02\", \"user_only\",             \"user_only\",       {}),\n",
    "    (\"E03\", \"item_attr_only\",        \"item_attr_only\",  {}),\n",
    "    (\"E04\", \"item_pop_only\",         \"item_pop_only\",   {}),\n",
    "    (\"E05\", \"ui_only\",               \"ui_only\",         {}),\n",
    "    (\"E06\", \"user_plus_ui\",          \"user+ui\",         {}),\n",
    "    (\"E07\", \"item_attr_plus_pop\",    \"item_attr+pop\",   {}),\n",
    "    (\"E08\", \"all_minus_ui\",          \"all_minus_ui\",    {}),\n",
    "    (\"E09\", \"all_minus_pop\",         \"all_minus_pop\",   {}),\n",
    "\n",
    "    (\"E10\", \"stronger_reg\",          \"all\", {\"min_data_in_leaf\":200, \"reg_lambda\":5.0, \"reg_alpha\":1.0}),\n",
    "    (\"E11\", \"lr_0.03_more_trees\",    \"all\", {\"learning_rate\":0.03, \"n_estimators\":4000}),\n",
    "    (\"E12\", \"extra_trees\",           \"all\", {\"extra_trees\":True}),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for exp_id, exp_name, feat_set_name, override in EXPS:\n",
    "    feats = FEATURE_SETS[feat_set_name]\n",
    "    params = {**BASE_PARAMS, **override}\n",
    "\n",
    "    X_train_fs = train_df[feats]\n",
    "    X_val_fs   = val_df[feats]\n",
    "\n",
    "    row = run_experiment(\n",
    "        exp_id=exp_id,\n",
    "        exp_name=exp_name,\n",
    "        recall_name=\"final_merged_recall_v1\",\n",
    "        lgb_params=params,\n",
    "        X_train=X_train_fs, y_train=y_train, group_train=group_train,\n",
    "        X_val=X_val_fs, y_val=y_val, group_val=group_val,\n",
    "        rank_df_val_for_eval=rank_df_val_for_eval\n",
    "    )\n",
    "    rows.append(row)\n",
    "    print(exp_id, exp_name, feat_set_name, row[\"val_map12_manual\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = dict(\n",
    "#     objective=\"lambdarank\",\n",
    "#     metric=\"ndcg\",\n",
    "#     eval_at=[12],\n",
    "#     learning_rate=0.05,\n",
    "#     n_estimators=2000,\n",
    "#     num_leaves=63,\n",
    "#     min_data_in_leaf=50,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8,\n",
    "#     reg_lambda=1.0,\n",
    "#     random_state=SEED,\n",
    "#     bagging_seed=SEED,\n",
    "#     feature_fraction_seed=SEED,\n",
    "#     data_random_seed=SEED,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# row = run_experiment(\n",
    "#     exp_id=\"E01\",\n",
    "#     exp_name=\"baseline\",\n",
    "#     recall_name=\"final_merged_recall_v1\",\n",
    "#     lgb_params=params,\n",
    "#     X_train=X_train, y_train=y_train, group_train=group_train,\n",
    "#     X_val=X_val, y_val=y_val, group_val=group_val,\n",
    "#     rank_df_val_for_eval=rank_df_val_for_eval\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f321d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_id</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>recall_name</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>best_iteration</th>\n",
       "      <th>train_time_sec</th>\n",
       "      <th>val_map12_manual</th>\n",
       "      <th>num_train_rows</th>\n",
       "      <th>num_val_rows</th>\n",
       "      <th>num_features</th>\n",
       "      <th>model_path</th>\n",
       "      <th>config_path</th>\n",
       "      <th>val_avg_candidates</th>\n",
       "      <th>val_med_candidates</th>\n",
       "      <th>val_min_candidates</th>\n",
       "      <th>val_max_candidates</th>\n",
       "      <th>val_pos_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E08</td>\n",
       "      <td>all_minus_ui</td>\n",
       "      <td>final_merged_recall_v1</td>\n",
       "      <td>2025-12-30 23:01:46</td>\n",
       "      <td>122</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.030973</td>\n",
       "      <td>2822015</td>\n",
       "      <td>705548</td>\n",
       "      <td>12</td>\n",
       "      <td>../models/E08_all_minus_ui.pkl</td>\n",
       "      <td>../experiments/configs/E08_all_minus_ui.json</td>\n",
       "      <td>51.137784</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>0.002694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E09</td>\n",
       "      <td>all_minus_pop</td>\n",
       "      <td>final_merged_recall_v1</td>\n",
       "      <td>2025-12-30 23:02:03</td>\n",
       "      <td>139</td>\n",
       "      <td>10.18</td>\n",
       "      <td>0.033097</td>\n",
       "      <td>2822015</td>\n",
       "      <td>705548</td>\n",
       "      <td>11</td>\n",
       "      <td>../models/E09_all_minus_pop.pkl</td>\n",
       "      <td>../experiments/configs/E09_all_minus_pop.json</td>\n",
       "      <td>51.137784</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>0.002694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E10</td>\n",
       "      <td>stronger_reg</td>\n",
       "      <td>final_merged_recall_v1</td>\n",
       "      <td>2025-12-30 23:02:24</td>\n",
       "      <td>197</td>\n",
       "      <td>14.43</td>\n",
       "      <td>0.037007</td>\n",
       "      <td>2822015</td>\n",
       "      <td>705548</td>\n",
       "      <td>14</td>\n",
       "      <td>../models/E10_stronger_reg.pkl</td>\n",
       "      <td>../experiments/configs/E10_stronger_reg.json</td>\n",
       "      <td>51.137784</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>0.002694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E11</td>\n",
       "      <td>lr_0.03_more_trees</td>\n",
       "      <td>final_merged_recall_v1</td>\n",
       "      <td>2025-12-30 23:02:36</td>\n",
       "      <td>20</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.036905</td>\n",
       "      <td>2822015</td>\n",
       "      <td>705548</td>\n",
       "      <td>14</td>\n",
       "      <td>../models/E11_lr_0.03_more_trees.pkl</td>\n",
       "      <td>../experiments/configs/E11_lr_0.03_more_trees....</td>\n",
       "      <td>51.137784</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>0.002694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E12</td>\n",
       "      <td>extra_trees</td>\n",
       "      <td>final_merged_recall_v1</td>\n",
       "      <td>2025-12-30 23:02:59</td>\n",
       "      <td>238</td>\n",
       "      <td>16.93</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>2822015</td>\n",
       "      <td>705548</td>\n",
       "      <td>14</td>\n",
       "      <td>../models/E12_extra_trees.pkl</td>\n",
       "      <td>../experiments/configs/E12_extra_trees.json</td>\n",
       "      <td>51.137784</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>0.002694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exp_id            exp_name             recall_name            timestamp  best_iteration  train_time_sec  val_map12_manual  num_train_rows  num_val_rows  num_features  \\\n",
       "6     E08        all_minus_ui  final_merged_recall_v1  2025-12-30 23:01:46             122           11.11          0.030973         2822015        705548            12   \n",
       "7     E09       all_minus_pop  final_merged_recall_v1  2025-12-30 23:02:03             139           10.18          0.033097         2822015        705548            11   \n",
       "8     E10        stronger_reg  final_merged_recall_v1  2025-12-30 23:02:24             197           14.43          0.037007         2822015        705548            14   \n",
       "9     E11  lr_0.03_more_trees  final_merged_recall_v1  2025-12-30 23:02:36              20            5.03          0.036905         2822015        705548            14   \n",
       "10    E12         extra_trees  final_merged_recall_v1  2025-12-30 23:02:59             238           16.93          0.036079         2822015        705548            14   \n",
       "\n",
       "                              model_path                                        config_path  val_avg_candidates  val_med_candidates  val_min_candidates  val_max_candidates  val_pos_rate  \n",
       "6         ../models/E08_all_minus_ui.pkl       ../experiments/configs/E08_all_minus_ui.json           51.137784                51.0                  51                  57      0.002694  \n",
       "7        ../models/E09_all_minus_pop.pkl      ../experiments/configs/E09_all_minus_pop.json           51.137784                51.0                  51                  57      0.002694  \n",
       "8         ../models/E10_stronger_reg.pkl       ../experiments/configs/E10_stronger_reg.json           51.137784                51.0                  51                  57      0.002694  \n",
       "9   ../models/E11_lr_0.03_more_trees.pkl  ../experiments/configs/E11_lr_0.03_more_trees....           51.137784                51.0                  51                  57      0.002694  \n",
       "10         ../models/E12_extra_trees.pkl        ../experiments/configs/E12_extra_trees.json           51.137784                51.0                  51                  57      0.002694  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../experiments/exp_results.csv\").tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
