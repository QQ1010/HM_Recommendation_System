{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2adde42",
   "metadata": {},
   "source": [
    "### H&M Recommendation System — 02 Recall (Candidate Generation)\n",
    "\n",
    "In this notebook, I design and evaluate several **candidate generation (recall)** strategies\n",
    "for the H&M Personalized Fashion Recommendations task.\n",
    "\n",
    "Based on the EDA from `01_eda.ipynb`, I observed that:\n",
    "\n",
    "- Customer behavior shows a strong **long-tail distribution** with clear personal preferences\n",
    "  and repeated purchases of similar product types.\n",
    "- Article popularity is highly skewed, with a small subset of items dominating sales.\n",
    "- The transaction timeline exhibits a strong **weekly pattern**, as well as several large spikes\n",
    "  likely corresponding to promotional events.\n",
    "- Articles have rich and well-structured **categorical metadata** (e.g. product groups, sections,\n",
    "  garment groups), which provide useful semantic information.\n",
    "- Customers frequently buy multiple items in a single day, indicating strong **co-purchase patterns**.\n",
    "\n",
    "These observations motivate the following recall strategies:\n",
    "\n",
    "1. **User-history-based recall**  \n",
    "   - Use each customer's historical purchases (from the training period) as personalized candidates.\n",
    "\n",
    "2. **Recent popularity recall**  \n",
    "   - Use globally trending items from a recent time window (e.g. last 28 days before validation)\n",
    "     as a popularity-based candidate pool.\n",
    "\n",
    "3. **Category-based recall**  \n",
    "   - Use item metadata (e.g. product_type or product_group) to recommend popular items from\n",
    "     the categories that a user frequently buys.\n",
    "\n",
    "4. **Co-purchase-based recall**  \n",
    "   - Use simple co-purchase statistics (\"customers who bought A also bought B\") to find items\n",
    "     related to a user's previously purchased products.\n",
    "\n",
    "Together, these recall pools aim to cover:\n",
    "- **Personal preferences** (user history)\n",
    "- **Global trends** (recent popularity)\n",
    "- **Semantic similarity** (category-based)\n",
    "- **Behavioral complementarity** (co-purchase)\n",
    "\n",
    "The final candidate set (top 100 ~ 500) for each customer will be built by combining these pools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a24a6c",
   "metadata": {},
   "source": [
    "#### Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aaabfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 5)\n",
    "pd.set_option(\"display.max_rows\", 5)\n",
    "\n",
    "DATA_DIR = \"../hm_data\"\n",
    "RES_DIR = \"../data/recall\"\n",
    "TRAIN_DIR = \"../data/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba5e176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transactions: (31788324, 5)\n",
      "articles: (105542, 25)\n"
     ]
    }
   ],
   "source": [
    "# Load transactions\n",
    "transactions = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"transactions_train.csv\"),\n",
    "    parse_dates=[\"t_dat\"]\n",
    ")\n",
    "print(\"transactions:\", transactions.shape)\n",
    "\n",
    "# Load articles metadata (for category-based recall)\n",
    "articles = pd.read_csv(os.path.join(DATA_DIR, \"articles.csv\"))\n",
    "print(\"articles:\", articles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e253b1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2018-09-20 00:00:00'), Timestamp('2020-09-22 00:00:00'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions[\"t_dat\"].min(), transactions[\"t_dat\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa949531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save recall results\n",
    "def save_pickle(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7542bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID_START: 2020-09-16 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (31548013, 5) Valid: (240311, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split Train / Valid\n",
    "VALID_START = pd.to_datetime(\"2020-09-16\")\n",
    "print(\"VALID_START:\", VALID_START)\n",
    "\n",
    "train_df = transactions[transactions[\"t_dat\"] < VALID_START].copy()\n",
    "valid_df = transactions[transactions[\"t_dat\"] >= VALID_START].copy()\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Valid:\", valid_df.shape)\n",
    "\n",
    "save_pickle(train_df, os.path.join(TRAIN_DIR, \"train_df.pkl\"))\n",
    "save_pickle(valid_df, os.path.join(TRAIN_DIR, \"valid_df.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7cb408",
   "metadata": {},
   "source": [
    "#### Step 2: Validation Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06230ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gt = (\n",
    "    valid_df.groupby(\"customer_id\")[\"article_id\"]\n",
    "    .apply(lambda x: set(x.astype(int)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "len(valid_gt)\n",
    "save_pickle(valid_gt, os.path.join(TRAIN_DIR, \"validation_groundtruth.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952665c",
   "metadata": {},
   "source": [
    "#### Step 3: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a13cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Recall@K & Hit Rate\n",
    "def evaluate_recall(candidates_dict, gt_dict, k=100, return_recalls=False):\n",
    "    \"\"\"\n",
    "    candidates_dict: {customer_id: [candidate_item_ids]}\n",
    "    gt_dict: {customer_id: set(ground_truth_items)}\n",
    "    \"\"\"\n",
    "    recalls = []\n",
    "    hits = 0\n",
    "    total_users = 0\n",
    "\n",
    "    for cust, gt_items in gt_dict.items():\n",
    "        if cust not in candidates_dict:\n",
    "            continue\n",
    "        total_users += 1\n",
    "\n",
    "        cand = candidates_dict[cust][:k]\n",
    "        cand_set = set(cand)\n",
    "        inter = cand_set & gt_items\n",
    "\n",
    "        if len(gt_items) > 0:\n",
    "            recall_u = len(inter) / len(gt_items)\n",
    "            recalls.append(recall_u)\n",
    "\n",
    "        if len(inter) > 0:\n",
    "            hits += 1\n",
    "\n",
    "    mean_recall = float(np.mean(recalls)) if recalls else 0.0\n",
    "    hit_rate = hits / total_users if total_users > 0 else 0.0\n",
    "\n",
    "    result = {\n",
    "        f\"mean_recall@{k}\": mean_recall,\n",
    "        f\"hit_rate@{k}\": hit_rate,\n",
    "        \"num_users\": total_users,\n",
    "    }\n",
    "    if return_recalls:\n",
    "        return result, recalls\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa57660",
   "metadata": {},
   "source": [
    "#### 1. User-history-based recall\n",
    "\n",
    "Idea:\n",
    "- For each customer, use their historical purchases in the **training period**\n",
    "  as personalized candidate items.\n",
    "- We keep only the most recent N items per user to control candidate size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbb58b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356709\n",
      "[User-history] Recall@12: {'mean_recall@12': 0.010695502032411243, 'hit_rate@12': 0.019050022077840158, 'num_users': 63412}\n",
      "[User-history] Recall@50: {'mean_recall@50': 0.029676517897718507, 'hit_rate@50': 0.054374566328139785, 'num_users': 63412}\n",
      "[User-history] Recall@100: {'mean_recall@100': 0.042171081995056175, 'hit_rate@100': 0.0793225257049139, 'num_users': 63412}\n"
     ]
    }
   ],
   "source": [
    "# Sort by customer and date\n",
    "train_df_sorted = train_df.sort_values([\"customer_id\", \"t_dat\"])\n",
    "\n",
    "MAX_HISTORY_ITEMS = 150\n",
    "\n",
    "user_hist_items = (\n",
    "    train_df_sorted.groupby(\"customer_id\")[\"article_id\"]\n",
    "    .apply(lambda x: list(x.astype(int).tail(MAX_HISTORY_ITEMS)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "print(len(user_hist_items))\n",
    "\n",
    "user_history_candidates = user_hist_items\n",
    "\n",
    "for k in [12, 50, 100]:\n",
    "    metrics = evaluate_recall(user_history_candidates, valid_gt, k=k)\n",
    "    print(f\"[User-history] Recall@{k}:\", metrics)\n",
    "\n",
    "save_pickle(user_history_candidates, os.path.join(RES_DIR, \"recall_user_history.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6853c2d",
   "metadata": {},
   "source": [
    "#### 2. Recent Popularity Recall\n",
    "\n",
    "Idea:\n",
    "- Compute globally popular items based on a **recent time window** before validation\n",
    "  (e.g., last 28 days).\n",
    "- Use the same set of trending items as candidates for all customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d9cff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent window: 2020-08-19 00:00:00 to 2020-09-15 00:00:00\n",
      "Recent df shape: (1059723, 5)\n",
      "article_id\n",
      "751471001    2758\n",
      "706016001    2408\n",
      "             ... \n",
      "916468003    1822\n",
      "448509014    1807\n",
      "Name: customer_id, Length: 10, dtype: int64\n",
      "[Recent popularity] Recall@12: {'mean_recall@12': 0.0193215469061964, 'hit_rate@12': 0.04970717847616839, 'num_users': 68984}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Recent popularity] Recall@50: {'mean_recall@50': 0.061846482469658876, 'hit_rate@50': 0.14835324133132322, 'num_users': 68984}\n",
      "[Recent popularity] Recall@100: {'mean_recall@100': 0.10520628280566931, 'hit_rate@100': 0.23590977617998377, 'num_users': 68984}\n"
     ]
    }
   ],
   "source": [
    "RECENT_DAY = 28\n",
    "recent_start = VALID_START - timedelta(days=RECENT_DAY)\n",
    "\n",
    "recent_df = train_df[train_df[\"t_dat\"] >= recent_start]\n",
    "print(\"Recent window:\", recent_df[\"t_dat\"].min(), \"to\", recent_df[\"t_dat\"].max())\n",
    "print(\"Recent df shape:\", recent_df.shape)\n",
    "\n",
    "recent_popularity = (\n",
    "    recent_df.groupby(\"article_id\")[\"customer_id\"]\n",
    "    .count()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(recent_popularity.head(10))\n",
    "\n",
    "TOPK_RECENT = 200\n",
    "top_recent_items = list(recent_popularity.index.astype(int)[:TOPK_RECENT])\n",
    "\n",
    "recent_pop_candidates = {cust: top_recent_items for cust in valid_gt.keys()}\n",
    "\n",
    "for k in [12, 50, 100]:\n",
    "    metrics = evaluate_recall(recent_pop_candidates, valid_gt, k=k)\n",
    "    print(f\"[Recent popularity] Recall@{k}:\", metrics)\n",
    "\n",
    "save_pickle(recent_pop_candidates, os.path.join(RES_DIR, \"recall_recent_popularity.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "052e843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id\n",
      "product_code\n",
      "prod_name\n",
      "product_type_no\n",
      "product_type_name\n",
      "product_group_name\n",
      "graphical_appearance_no\n",
      "graphical_appearance_name\n",
      "colour_group_code\n",
      "colour_group_name\n",
      "perceived_colour_value_id\n",
      "perceived_colour_value_name\n",
      "perceived_colour_master_id\n",
      "perceived_colour_master_name\n",
      "department_no\n",
      "department_name\n",
      "index_code\n",
      "index_name\n",
      "index_group_no\n",
      "index_group_name\n",
      "section_no\n",
      "section_name\n",
      "garment_group_no\n",
      "garment_group_name\n",
      "detail_desc\n"
     ]
    }
   ],
   "source": [
    "for col in articles.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a13f78",
   "metadata": {},
   "source": [
    "#### 3. Category-based Recall\n",
    "\n",
    "Idea:\n",
    "- Use article metadata (e.g., `product_type_name` or `product_group_name`) to build\n",
    "  category-level popularity tables.\n",
    "- For each user, identify their **favorite categories** based on training history.\n",
    "- Recommend **popular items within those categories** as candidates.\n",
    "\n",
    "This helps:\n",
    "- Cover items that are semantically similar to what the user likes.\n",
    "- Go beyond exact repeats of previously purchased items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aeac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id product_type_name  product_group_name\n",
      "0   108775015          Vest top  Garment Upper body\n",
      "1   108775044          Vest top  Garment Upper body\n",
      "2   108775051          Vest top  Garment Upper body\n",
      "3   110065001               Bra           Underwear\n",
      "4   110065002               Bra           Underwear\n",
      "                                         customer_id  article_id      t_dat  \\\n",
      "0  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   663713001 2018-09-20   \n",
      "1  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   541518023 2018-09-20   \n",
      "2  00007d2de826758b65a93dd24ce629ed66842531df6699...   505221004 2018-09-20   \n",
      "3  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687003 2018-09-20   \n",
      "4  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687004 2018-09-20   \n",
      "\n",
      "  product_type_name  product_group_name  \n",
      "0    Underwear body           Underwear  \n",
      "1               Bra           Underwear  \n",
      "2           Sweater  Garment Upper body  \n",
      "3           Sweater  Garment Upper body  \n",
      "4           Sweater  Garment Upper body  \n"
     ]
    }
   ],
   "source": [
    "cat_cols = [\"article_id\", \"product_type_name\"]\n",
    "articles_cat = articles[cat_cols].copy()\n",
    "print(articles_cat.head())\n",
    "\n",
    "# build article_id -> category dict\n",
    "article_to_ptype = dict(zip(articles_cat[\"article_id\"].astype(int),\n",
    "                            articles_cat[\"product_type_name\"]))\n",
    "\n",
    "train_cat = train_df[[\"customer_id\", \"article_id\", \"t_dat\"]].copy()\n",
    "train_cat[\"article_id\"] = train_cat[\"article_id\"].astype(int)\n",
    "train_cat[\"product_type_name\"] = train_cat[\"article_id\"].map(article_to_ptype)\n",
    "\n",
    "print(train_cat.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5d0d87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>Blazer</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>Dress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>Gloves</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>Hoodie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>Jacket</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id product_type_name  cnt\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...            Blazer    5\n",
       "1  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...             Dress    1\n",
       "2  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...            Gloves    1\n",
       "3  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...            Hoodie    1\n",
       "4  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...            Jacket    3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of purchases per user across different product_type_no\n",
    "user_type_counts = (\n",
    "    train_cat.groupby([\"customer_id\", \"product_type_name\"])[\"article_id\"]\n",
    "    .count()\n",
    "    .reset_index(name=\"cnt\")\n",
    ")\n",
    "user_type_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dbab4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_491911/565893812.py:10: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(top_categories_for_user)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356709\n"
     ]
    }
   ],
   "source": [
    "# Get the top N categories for each user\n",
    "TOP_CATEGORIES_PER_USER = 3\n",
    "\n",
    "def top_categories_for_user(df):\n",
    "    df_sorted = df.sort_values(\"cnt\", ascending=False)\n",
    "    return list(df_sorted[\"product_type_name\"].head(TOP_CATEGORIES_PER_USER))\n",
    "\n",
    "user_top_types = (\n",
    "    user_type_counts.groupby(\"customer_id\")\n",
    "    .apply(top_categories_for_user)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "print(len(user_top_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d377ebcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>article_id</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accessories set</td>\n",
       "      <td>755356001</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accessories set</td>\n",
       "      <td>858306002</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accessories set</td>\n",
       "      <td>858306003</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accessories set</td>\n",
       "      <td>858306005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accessories set</td>\n",
       "      <td>858306006</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_type_name  article_id  cnt\n",
       "0   Accessories set   755356001   11\n",
       "1   Accessories set   858306002    7\n",
       "2   Accessories set   858306003   12\n",
       "3   Accessories set   858306005    1\n",
       "4   Accessories set   858306006   11"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# During training, the most popular items within each product_type_name\n",
    "type_item_pop = (\n",
    "    train_cat.groupby([\"product_type_name\", \"article_id\"])[\"customer_id\"]\n",
    "    .count()\n",
    "    .reset_index(name=\"cnt\")\n",
    ")\n",
    "\n",
    "type_item_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c70ee903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TYPE_TOP_ITEMS = 50  # The top 50 most popular items in each category\n",
    "\n",
    "type_to_top_items = {}\n",
    "for ptype, subdf in type_item_pop.groupby(\"product_type_name\"):\n",
    "    sub_sorted = subdf.sort_values(\"cnt\", ascending=False)\n",
    "    type_to_top_items[ptype] = list(sub_sorted[\"article_id\"].astype(int).head(TYPE_TOP_ITEMS))\n",
    "\n",
    "len(type_to_top_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b444f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356709\n"
     ]
    }
   ],
   "source": [
    "# Create Category-based candidates for each user\n",
    "MAX_PER_USER = 200\n",
    "category_candidates = {}\n",
    "for cust, types in user_top_types.items():\n",
    "    cand_list = []\n",
    "    for t in types:\n",
    "        cand_list.extend(type_to_top_items.get(t, []))\n",
    "    seen = set()\n",
    "    final_cand_list = []\n",
    "    for item in cand_list:\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            final_cand_list.append(item)\n",
    "    category_candidates[cust] = final_cand_list[:MAX_PER_USER]\n",
    "print(len(category_candidates))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8785f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Category-based] Recall@12: {'mean_recall@12': 0.007771040348258594, 'hit_rate@12': 0.019665047625055193, 'num_users': 63412}\n",
      "[Category-based] Recall@50: {'mean_recall@50': 0.016429647358185674, 'hit_rate@50': 0.03926701570680628, 'num_users': 63412}\n",
      "[Category-based] Recall@100: {'mean_recall@100': 0.026399832303020003, 'hit_rate@100': 0.0640415063394941, 'num_users': 63412}\n"
     ]
    }
   ],
   "source": [
    "for k in [12, 50, 100]:\n",
    "    metrics = evaluate_recall(category_candidates, valid_gt, k=k)\n",
    "    print(f\"[Category-based] Recall@{k}:\", metrics)\n",
    "\n",
    "save_pickle(category_candidates, os.path.join(RES_DIR, \"recall_category.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f665f3",
   "metadata": {},
   "source": [
    "#### 4. Co-purchase-based Recall\n",
    "\n",
    "Idea:\n",
    "- Treat all items purchased by the same customer on the same day as a \"basket\".\n",
    "- For each item A, count how many times it co-occurs with other items B in the same basket.\n",
    "- For each user, look at their purchased items and recommend items that are frequently\n",
    "  co-purchased with them.\n",
    "- To avoid expensive cost, restricting to a subset of transactions (e.g. recent months or popular items).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7741cef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                         customer_id      t_dat  \\\n",
       " 0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3... 2020-09-05   \n",
       " 1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e... 2020-07-08   \n",
       " 2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca... 2020-09-15   \n",
       " 3  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f... 2020-08-12   \n",
       " 4  0000757967448a6cb83efb3ea7a3fb9d418ac7adf2379d... 2020-09-14   \n",
       " \n",
       "                                          basket  \n",
       " 0                                   [568601043]  \n",
       " 1                                   [826211002]  \n",
       " 2                                   [794321007]  \n",
       " 3  [730683050, 896152002, 927530004, 791587015]  \n",
       " 4                        [719530003, 448509014]  ,\n",
       " (1214591, 3))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COPURCHASE_RECENT_DAYS = 90\n",
    "cop_start = VALID_START - timedelta(days=COPURCHASE_RECENT_DAYS)\n",
    "cop_train = train_df[train_df[\"t_dat\"] >= cop_start].copy()\n",
    "\n",
    "basket_df = (\n",
    "    cop_train.groupby([\"customer_id\", \"t_dat\"])[\"article_id\"]\n",
    "    .apply(lambda x: list(set(x.astype(int))))\n",
    "    .reset_index(name=\"basket\")\n",
    ")\n",
    "\n",
    "basket_df.head(), basket_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f525ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41627"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate item → co-purchased items\n",
    "co_counts = defaultdict(Counter)\n",
    "\n",
    "for row in basket_df[\"basket\"]:\n",
    "    # empty basket\n",
    "    if len(row) <= 1:\n",
    "        continue\n",
    "    for i in row:\n",
    "        for j in row:\n",
    "            if i == j:\n",
    "                continue\n",
    "            co_counts[i][j] += 1\n",
    "\n",
    "len(co_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e631f8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41627"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each item, take the top N co-purchased items.\n",
    "TOP_CO_ITEMS = 10\n",
    "\n",
    "item_co_candidates = {}\n",
    "for item, counter in co_counts.items():\n",
    "    item_co_candidates[int(item)] = [j for j, c in counter.most_common(TOP_CO_ITEMS)]\n",
    "\n",
    "len(item_co_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4faf8071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1245226"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_copurchase_candidates(user_hist_dict, item_co_dict, max_per_user=200):\n",
    "    user_cands = {}\n",
    "    for cust, hist_items in user_hist_dict.items():\n",
    "        related = []\n",
    "        for it in hist_items:\n",
    "            related.extend(item_co_dict.get(it, []))\n",
    "        if not related:\n",
    "            continue\n",
    "        counter = Counter(related)\n",
    "        sorted_items = [i for i, c in counter.most_common(max_per_user)]\n",
    "        user_cands[cust] = sorted_items\n",
    "    return user_cands\n",
    "\n",
    "copurchase_candidates = build_copurchase_candidates(\n",
    "    user_hist_items, item_co_candidates, max_per_user=200\n",
    ")\n",
    "\n",
    "len(copurchase_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac4edeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Co-purchase] Recall@12: {'mean_recall@12': 0.017769848957451848, 'hit_rate@12': 0.04253899672776948, 'num_users': 62954}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Co-purchase] Recall@50: {'mean_recall@50': 0.041809497027143885, 'hit_rate@50': 0.09500587730724021, 'num_users': 62954}\n",
      "[Co-purchase] Recall@100: {'mean_recall@100': 0.05823925536719977, 'hit_rate@100': 0.13036502843345935, 'num_users': 62954}\n"
     ]
    }
   ],
   "source": [
    "for k in [12, 50, 100]:\n",
    "    metrics = evaluate_recall(copurchase_candidates, valid_gt, k=k)\n",
    "    print(f\"[Co-purchase] Recall@{k}:\", metrics)\n",
    "\n",
    "save_pickle(category_candidates, os.path.join(RES_DIR, \"recall_copurchase.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0f138",
   "metadata": {},
   "source": [
    "#### 5. Combine Recall Pools\n",
    "\n",
    "Now combine different recall strategies into a single candidate set per user:\n",
    "\n",
    "- User-history-based candidates\n",
    "- Recent popularity candidates\n",
    "- Category-based candidates\n",
    "- Co-purchase candidates\n",
    "\n",
    "Take the union of these sets and limit the total number of candidates per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "868e9835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1362281"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_candidates(*cand_dicts, max_per_user=300):\n",
    "    merged = {}\n",
    "    all_customers = set()\n",
    "    for d in cand_dicts:\n",
    "        all_customers.update(d.keys())\n",
    "\n",
    "    for cust in all_customers:\n",
    "        seen = set()\n",
    "        merged_list = []\n",
    "        for d in cand_dicts:\n",
    "            items = d.get(cust, [])\n",
    "            for it in items:\n",
    "                if it not in seen:\n",
    "                    seen.add(it)\n",
    "                    merged_list.append(it)\n",
    "                    if len(merged_list) >= max_per_user:\n",
    "                        break\n",
    "            if len(merged_list) >= max_per_user:\n",
    "                break\n",
    "        merged[cust] = merged_list\n",
    "    return merged\n",
    "\n",
    "final_candidates = merge_candidates(\n",
    "    user_history_candidates,\n",
    "    recent_pop_candidates,\n",
    "    category_candidates,\n",
    "    copurchase_candidates,\n",
    "    max_per_user=300\n",
    ")\n",
    "\n",
    "len(final_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adc5959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Final merged] Recall@50: {'mean_recall@50': 0.05731768677567743, 'hit_rate@50': 0.11478023889597588, 'num_users': 68984}\n",
      "[Final merged] Recall@100: {'mean_recall@100': 0.1078970009319, 'hit_rate@100': 0.21726777223704047, 'num_users': 68984}\n",
      "[Final merged] Recall@200: {'mean_recall@200': 0.1783868461271448, 'hit_rate@200': 0.3498347442885307, 'num_users': 68984}\n",
      "[Final merged] Recall@300: {'mean_recall@300': 0.20418784585142544, 'hit_rate@300': 0.3909892148904094, 'num_users': 68984}\n"
     ]
    }
   ],
   "source": [
    "for k in [50, 100, 200, 300]:\n",
    "    metrics = evaluate_recall(final_candidates, valid_gt, k=k)\n",
    "    print(f\"[Final merged] Recall@{k}:\", metrics)\n",
    "    \n",
    "save_pickle(final_candidates, os.path.join(RES_DIR, \"recall_final_merged.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
